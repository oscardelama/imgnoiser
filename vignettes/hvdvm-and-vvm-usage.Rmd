---
title: "*hvdvm* and *vvm* Class Usage"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    css: odlvignette.css
    number_sections: yes
vignette: >
  %\VignetteIndexEntry{hvdvm and vvm Class Usage}
  %\VignetteEngine{knitr::rmarkdown}
  %\usepackage[utf8]{inputenc}
---

```{r echo = FALSE, message = FALSE}
library(imgnoiser)
options(digits=4)
test.data.folder <- imgnoiser:::get.test.data.folder()
samples.count <- 84

knitr::opts_chunk$set(
   comment = "#>"
  ,prompt = FALSE
  ,collapse = TRUE
  ,dev = 'png'
  ,tidy = FALSE
)
#render("./vignettes/hvdvm-and-vvm-usage.Rmd", output_format='md_document')
```

The `hvdvm` and the `vvm` classes process the raw image samples in different way, and correspondingly their output must be interpreted in different way. From the point of view of these classes implementation, this means they have very different `digest()` function and the data in their `var.df` and `cov.df` variables have different meanings. However, from an operational point of view, everything else in these classes works in the same way and with the same semantics. Of course, everything derived from their data, as plot or a fitted models must be interpreted considering the nature of their data.

This vignette describes the functionality in the *hvdvm* and the *vvm* classes with the same behaviour. Before to read this vignette we encourage you to read first the  [*"hvdvm class usage"*](hvdvm-introduction.html) or the [*"vvm class usage"*](vvm-introduction.html) vignette, because this one is the follow up of both of them.

In the examples, instead of the `my.hvdvm` or the `my.vvm` object ---when possible--- we will use `my.obj` to represent an object that can be instance of `hvdvm` or the `vvm` class.

In the code examples, the function output is presented prefixed by `#>`, while a single `#` represents real (user) comments.

<div id="TOC">
<div class="toctitle">Table of Contents </div>
- [Getting Help about the Class components](#get-help)
- [Introduction to Model Fitting](#intro-fit)  
    * [Model Data Source](#model-data)
    * [Model Family](#model-family)
- [Fitting a Model](#model-fit)
    * [Model Predictions](#model-pred)
    * [Model Summary](#model-sum)
    * [Model Objects](#model-obj)
    * [List, Query and Remove Fitted Models](#lqrem)
- [Plotting](#plot)
- [Persistence](#persist)
</div>

# Getting Help about a Class Components # {#get-help}

In the following sections we will focus on the concepts and general workflow using the `hvdvm` or the `vvm` class. If you want more complete information about technical details, as which parameters are available for a given function, please use the R help system. In this section we will see how to get help about those  classes components.

To get the documentation of the `new()` function in the class `hvdvm`, one would expect the use of either of the following equivalent R commands:

```{r eval=FALSE}
?hvdvm$new
help('hvdvm$new')
```

However, the first one won't work and will throw you an error. The second one will work just fine. 

The first case `?hvdvm$new` fails because the use of R6 classes in the style made for the development of the `imgnoiser` package is rather new and the R help system is not ready for them yet. To call the help documentation, use the second way as in `help('hvdvm$new')`. 

If you don't recall which functions are available in a class instance, just "print"" it and you will get a list of the class members.

```{r }
getwd()
my.vvm <- vvm$new()
# This command will 'print' the instance
my.vvm
```

The components whose name start with a period `.` are intended for internal use only, please just ignore them.

Now, if ---for example--- you want to know more detail about the `fit.model()` function, in the above list, &mdash;as we saw above&mdash; you can use:

```{r eval=FALSE}
help('vvm$fit.model')
```

If you don't have a class instance, you can easily get an overview of the `hvdvm` class components, with the following command.

```{r eval=FALSE}
?hvdvm.class
```

You will get a list of the class functions with links to more detailed documentation of the `hvdvm` class components. The same applies to the `vvm` class.

```{r echo=FALSE, message=FALSE, results="hide"}
imgnoiser.option('show.progress', FALSE)
my.hvdvm <- hvdvm$new(has.RGGB.pattern = TRUE)
my.vvm <- vvm$new(has.RGGB.pattern = TRUE)
# test.data.folder <- '../data-raw/'
my.hvdvm$digest(paste0(test.data.folder,'iso100White.csv'), test.data.folder)
my.vvm$digest('crop_1', 'crop_240', test.data.folder, '.fit')
```

# Introduction to Model Fitting # {#intro-fit}

The concept of model in the `imgnoiser` package involves two concepts:

1. *Model Data*: The specific data which will be used as the observations over which we want to fit a model.
2. *Model Family*: The mathematical model we want to fit over the data mentioned in the previous point. 

## Model Data Source ## {#model-data}

Actually, only one data source exists by default and its called the standard data model and its named `std.var`. This model comes from the *variance* result we got after calling to the `hvdvm$digest()` function. More precisely, the `std.var` data model contains part of the data we get reading the `my.obj$var.df` variable. In this standard model, `mean` is the predictor variable (x) and `var` is the predicted one; and this pair of (x, y) observations are grouped by `channel`.

You can add more data models at your taste by changing the `get.model.predictions` option value. 

When a function requires, as an argument (`model.data.name`), the name of a data source, by default, it will use the `fit.model.data` option value, which as you might guess, by default, is `std.var`. 

Unless you provide more models, leave the default value for those `model.data.name` arguments, as we will do in the following examples.

## Model Family ## {#model-family}

We can choose, among different statistical models, the one that we want to fit to the data source. We group those models by the R function that actually makes the fitting. 

By default, the following *model families*, from the `stat` package, are available:

* `lm`
* `lmrob`
* `smooth.spline`

As this fitting functions allow a wide variety of options, in fact directing them to different mathematical models or fitting procedures, we have a broader amount of options than may it seem at first glance. For example, you can use the `lm()` with weights.

When a function requires as an argument a model family, it will use by default the `fit.model.data` option value, which by default is `lm`.

You can add more fitting function at your taste by changing the `fit.model.family` option value.

# Fitting a Model # {#model-fit}

We can start using a simple (OLS: ordinary least squares) line fitting. To this effect we will leave the default value for all the `hvdvm$fit.model()` function arguments:

```{r eval=FALSE}
# Fit the default 'lm' model and save it with the default 'standard' name.
my.obj$fit.model()
```

```{r echo=FALSE }
my.vvm$fit.model()
```

```{r echo=FALSE, message=FALSE, results='hide'}
my.hvdvm$fit.model()
```

The output after the model fitting mentions the model family (`lm`), the formula (`formula`) and the source data (`data = model.src("std.var")`). If there would be other parameters in the calling to the `lm()` function, they will appear in this output. Everything sent to the fitting functions will appear in this output; nothing is sent "under the hood".

Notice we did not input a formula, it has been inferred from the source data model and by the default argument for the `degree` parameter, which for the `hvdvm` class is `1` for the `vvm` one is `2`. This argument indicates a linear relationship with the predicted variable `var` being predicted by a first or second degree polynomial on `mean`. If you set `degree = 3`, a cubic polynomial on `mean` will be fitted to predict the `var` variable, with `4` you will fit a bi-quadratic one and so on.

Instead of the `degree` you can directly set the `formula` argument for the fitting with the specific formula you want. In such cases, when you specify the formula, the `degree` argument is silently ignored.

Other of the default arguments in the call to the `my.obj$fit.model()` function we just did, is the name for the model we are fitting (`model.name` parameter). By default the function uses the `fit.model.name` option value; which by default is `standard`. 

We can call the `my.obj$fit.model()` function again but with an argument for the `model.name` parameter different to `standard` to do not overwrite the fitting we just did, or we can omit again this argument to overwrite that model.

Lets fit a weighted linear model using as weight the reciprocal squared values of the mean:

```{r eval=FALSE}
library(robustbase)
# This time we will set the model name and model family parameters
my.object$fit.model(model.name = 'weighted', weights=1/mean^2)
```

```{r echo=FALSE}
my.vvm$fit.model(model.name = 'weighted', weights=1/mean^2)
```
```{r echo=FALSE, message=FALSE, results='hide'}
my.hvdvm$fit.model(model.name = 'weighted', weights=1/mean^2)
```

Notice how we specify the `weights` argument, for the `lm` function, using the variable name in our model. All the parameters that don't correspond to the `my.obj$fit.model()` function are passed directly to the fitting function. This allows the use any and every parameter available for them.

## Model Predictions ## {#model-pred}

We can get the predictions from the `standard` model we just fit, by calling the `my.obj$get.model.predictions()` function with the default arguments:

```{r echo=TRUE, eval=FALSE }
# Get a data frame with the model predictions for the 'standard' model
preds <- my.obj$get.model.predictions()
head(preds)
```
```{r echo=FALSE, results='hide'}
preds <- my.vvm$get.model.predictions()
```
```{r, echo=FALSE, comment=" " } 
knitr::kable(head(preds), caption='**Model predictions: lm**', align=c('r','r','r','c','r','r'), digits=2)
```

The columns in the resulting data frame are:

1. `mean`: The predictor variable.
2. `var`: The predicted variable.
3. `channel`: The grouping factor.
4. `sderr`: The prediction standard error.
5. `lcl`: The lower confidence limit.
6. `ucl`: The upper confidence limit.

The confidence limits are computed using as *"confidence factor"* the `confid.factor` option value, currently when we fit the model calling the `fit.model()` function. By default this factor is `1.96`. You would set this option, to the value that suits you best, before calling the `fit.model()` function. However, given the predicted value and its standard error (`sderr`) in this function output, you can compute them again by yourself as in the following example.

```{r echo=TRUE, results='hide' }
# Confidence limits using 2.5 as confidence factor
preds$lcl <- preds$var - 2.5*preds$sderr
preds$ucl <- preds$var + 2.5*preds$sderr
head(preds)
```

```{r, echo = FALSE, comment=" " } 
knitr::kable(head(preds), caption='**Customized Confidence Limits**', align=c('r','r','r','c','r','r'), digits=2)
```

This model predictions span the complete range of predictor values in the original data source:

```{r, echo = FALSE, comment=" " } 
my.obj <- my.vvm
```

```{r eval=FALSE}
# Get the predictor range from predictions
pred.ranges <- t(sapply(split(preds$mean, preds$channel), range))
# Get the predictor range from source data
src.ranges <- t(sapply(split(my.obj$var.df$mean, my.obj$var.df$channel), range))
# Compare source and prediction ranges
data.frame('pred.bot' = pred.ranges[,1], 'pred.top' = pred.ranges[,2],
           'src.bot'  = src.ranges[,1],  'src.top'  = src.ranges[,2])
```

```{r echo=FALSE, comment=""}
# Get the predictor range from predictions
pred.ranges <- t(sapply(split(preds$mean, preds$channel), range))
# Get the predictor range from source data
src.ranges <- t(sapply(split(my.obj$var.df$mean, my.obj$var.df$channel), range))
# Compare source and prediction ranges
cmp.df <-
    data.frame('pred.bot' = pred.ranges[,1], 'pred.top' = pred.ranges[,2],
               'src.bot'  = src.ranges[,1],  'src.top'  = src.ranges[,2])

knitr::kable(cmp.df, caption="**Predictor vs Source data ranges**", align=c('l','r','r','r','r'))
```

There are 30 predictions per channel in this function results. When possible, 20 of them are equally spaced in the range of the predictor source data, plus 10 of them logarithmic equally spaced in that range. If that is not possible because there are zero or negative values in the predictor source range, there will be 30 equally spaced predictor values per channel. This makes this predicted data suitable for a nice plotting, which we will do later.

To get the predictions from a fitting model not named `standard`, as the `weighted` model we fit before, we just have to mention its name in the call to the `my.obj$get.model.predictions()` function.

```{r echo=TRUE, eval=FALSE}
# Get a data frame with the model predictions for the 'weighted' mode
my.obj$get.model.predictions('weighted')
```

```{r, echo = FALSE, comment=" " } 
knitr::kable(head(my.obj$get.model.predictions('weighted')), caption='**Model predictions: Weighted**', align=c('r','r','r','c','r','r'), digits=4)
```

## Model Summary ## {#model-sum}

To get the model summary, we call the `my.obj$print.model.summary()` function. 

As the source data is grouped by `channel`, there is a model fitted for each one of them. This fact gets reflected in the summary, which correspondingly, shows four sub-summaries.

```{r }
# Get a data frame with the model predictions
my.obj$print.model.summary()
```

Because we did not specify a model name in the call to the `my.obj$print.model.summary()` function, it has returned the `standard` model summary. To get the summary for the `weighted` model we fitted before, we must call the `my.obj$print.model.summary()` function specifying that model name. 

By default this function prints the summary of each fitted `channel`. You can use the `select` parameter to choose which specific models summaries you want. You can pick them by index value (between 1 and 4) or by `channel` label. For example, lets get the summary for the `Blue` channel in the `weighted` model:

```{r }
# Get a data frame with the model predictions
my.obj$print.model.summary('weighted', select='Blue')
```

This function calls the `base::summary()` function corresponding to the model family used for the model fitting. Those functions accepts other parameters you can also specify when calling to the `my.obj$print.model.summary()` function.

## Model Objects ## {#model-obj}

The R functions that actually fit the models, like `lm()` or `lmrob()`, return an object which can be used in other R functions supporting them.  

As a trivial example, lets say we want to predict the *variance* (`var` variable), according to our `standard` regression, for the `Blue` channel, corresponding to `mean` values between `1,000` to `2,000` in steps of `100` (like `1000`, `1100`, ..., `2000`) . 

As the prediction for those specific `mean` values are not available through the `my.obj$get.model.predictions()` function, we have to compute them using the model object as argument for the `predict()` function.

The function `my.obj$get.model()` returns a list with the model objects for all the channels fitted in a given model. As usual, without any argument, this function returns the model objects for the `standard` model.

```{r }
# Get a list with the 'standard' model fitting objects
std.model <- my.obj$get.model()
class(std.model)
names(std.model)
```

Now we can use the `Blue` channel model object to compute our desired predictions.

```{r echo=TRUE, eval=FALSE}
preds.mean <- data.frame(mean=seq(1000, 2000, by=100))
# Get the predictions for the Blue channel using the corresponding model object
preds.var <- predict(std.model[['Blue']], newdata=preds.mean)
preds <- data.frame(preds.mean, var=preds.var)
```

```{r, echo=FALSE, comment=" " } 
preds.mean <- data.frame(mean=seq(1000, 2000, by=100))
preds.var <- predict(std.model[['Blue']], newdata=preds.mean)
preds <- data.frame(preds.mean, var=preds.var)

knitr::kable(head(preds), caption='**Customized Model predictions**', align=c('r','r'), digits=4)
```

The `my.obj$get.model()` function has a `select` parameter to get a list with only selected models, i.e. for specific channels. We can select the channel by label or by index. For example, we will use the `confint()` function, to get the confidence intervals for the coefficients in the regression for the `Red` channel.

```{r echo=FALSE, message=FALSE, results='hide'}
my.obj <- my.hvdvm
```


```{r results='hide'}
# Confidence intervals for the 'Red' model parameters (from the 'standard' fitting)
models <- my.obj$get.model(select='Red')
confint(models[[1]])
```

```{r, echo=FALSE, comment=NA } 
knitr::kable(confint(models[[1]]))
```

## List, Query and Remove Fitted Models

The `hvdvm$model.list` variable provides a list with the models already fitted.

```{r }
# List the models fitted so far.
my.obj$model.list
```

The `my.obj$exists.model` function help us to find out if a particular model exists.

```{r }
# We have a model named 'weighted'
my.obj$exists.model('weighted')
# But we dont have other one called 'log-log'
my.obj$exists.model('log-log')
```

To remove a model, we call the, `my.obj$remove.model()` function. In this case, for security reasons, there is no default name, you must be specify it.

```{r }
# We have a model named 'standard' ...
my.obj$exists.model('standard')
# .. but we don't want it any more
my.obj$remove.model('standard')
# Now, it doesn't exists
my.obj$exists.model('standard')
```

# Plotting # {#plot}

```{r echo=FALSE}
shared.legend <- function(g1, g2, main, ylab) {
  library(ggplot2)
  library(gridExtra)

  select <- function(x) {
    if ('name' %in% names(x))
      x$name
    else
      'NULL'
  }

  g_legend <- function(p){
    tmp <- ggplot2::ggplotGrob(p)
    leg <- which(sapply(tmp$grobs, select) == "guide-box")
    legend <- tmp$grobs[[leg]]
    return(legend)
  }

  legend <- g_legend(g1)
  lwidth <- sum(legend$width)

  # could also manually push viewports
  gridExtra::grid.arrange(gridExtra::arrangeGrob(g1 + ggplot2::theme(legend.position="none"),
                           g2 + ggplot2::theme(legend.position="none"),
                           main = main,
                           left = ylab), legend,
               widths=unit.c(unit(1, "npc") - lwidth, lwidth), nrow=1)
}
```

There is nothing like a good plot to let the data speak by itself, showing us its features, validating our assumptions or raising new questions.

With the data we get through the variables `my.obj$var.df`, `my.obj$cov.df`, `hvdvm$photo.conditions.df` and the `my.obj$get.model.predictions()` function, we can built any kind of plot we want. However the function `my.obj$plot()` provides an easy way to plot the data and a model already fitted, either together or individually.

By default, without any argument, the `my.obj$plot()` function just plots the standard data model observations. Using the `model.name` parameter, we can include a fitted model in the plot. As a convenience, if we set this parameter to `TRUE`, *the default model* will be plotted. As we already saw, this is the one with the same name as the `fit.model.name` option value, which by default is `standard`.

```{r fig.width=4, fig.height=4}
# Rebuild the previously deleted 'standard' model
my.obj$fit.model()
# Plot the 'standard' model
my.obj$plot(model.name = TRUE)
```

For the `model.name` parameter, instead of TRUE, you can use the name of the fitted model you want to plot.

The parameters `fit` and `confid` are relevant only when a fitted model is included in the plot. The `fit` parameter set to TRUE draws a line over the values predicted by the model. The `confid` parameter set to `TRUE` draws a semi-transparent area between the confidence limits of the predicted values. By default they are set to `TRUE` and `FALSE` respectively.

Using the `xlim` and ``ylim` parameters, you can force the `my.obj$plot()` function to draw only the particular area of the plot you are interested in. They must be a vector of two numeric values: the lower and upper limit of the corresponding axis.

You can also specify the axis labels with the parameters `xlab` and `ylab`. Furthermore, you can set the main and secondary titles with the `main` and `subt` parameters. For further customization you can set the `plot.point.size` and `plot.line.width` option values, which are used for the size of the points and the width of the lines in the plot. The `color.pallette` option is a vector with the  color pallette used in the plots. You can set it to NULL to use the ggplot2 default pallette or to whichever colors you want in the plots.

The `my.obj$plot()` function returns a `ggplot2::ggplot` object which you can use to customize the plot at your taste. To this effect tou can set the `print` parameter to `FALSE` to avoid the plot rendering, customize the received ggplot object, and print it whenever you are ready.

For example, the `standard` and the `weighted` plots are very much alike to each other, except in their interception to the `y` axis, close to the axes origin. To notice this, we will "plot" both models without printing them, with the `x` axis limits to the `0, 300` range and the y axis to `0, 150`. We will call to [this function](https://github.com/hadley/ggplot2/wiki/Share-a-legend-between-two-ggplot2-graphs), using those plot objects as arguments, to draw both plots sharing the same title, `y` axis label and legend.

```{r echo=FALSE, message=FALSE, results='hide'}
my.obj <- my.hvdvm
```


```{r fig.width=7, fig.height=6, results='hold', warning=FALSE}
# Get the OLS linear regression plot
std.plot <- my.obj$plot(model.name=TRUE, print=FALSE, 
                  xlab='Mean', ylab=NULL, main=NULL, xlim=c(0,300), ylim=c(0, 150))

# Get the weighted, robust, linear regression plot
weighted.plot <- my.obj$plot(model.name='weighted', print=FALSE, 
                  xlab='Mean', ylab=NULL, main=NULL, xlim=c(0,300), ylim=c(0, 150))

# Use both plot objects for detailed customization.
shared.legend(std.plot
             ,weighted.plot
             ,'Two plots sharing title, y label and legend'
             ,'Variance (ADU^2)'
             )
```

Now we can clearly notice how the OLS linear regression, misses the data trend close to the origin, while the weighted one correctly follows it.

# Persistence {#persist}

Using the `imgnoiser.save()` function we can save an instance object to a disk file, and later, in another R session, retrieve it with the function `imgnoiser.load()`. The files saved to disk have `.imn` as name extension.

By default when we save an object, we also save in the same file all the `imgnoiser` package options. Correspondingly, when we load an object, by default, we also load all the `imgnoiser` package options. The `save.options` and `load.options` parameters in those functions allows to change that behaviour and save or load the package options only when desired.

```{r echo=TRUE, eval=FALSE}
# Save the my.hvdvm object, and the package options, in a file named 'my.hvdvm'
imgnoiser.save(my.hvdvm)
# Save the my.hvdvm object in a particula path and file name without
# saving also the package options
imgnoiser.save(my.hvdvm, 'path/to/my.object', save.options = FALSE)

# Some days later, load the saved object, in another R session 
hvdvm.obj <- imgnoiser.load('path/to/my.object')
# Load the object but not the package options
hvdvm.obj <- imgnoiser.load('path/to/my.object', load.options = FALSE)
```


Additionally we can save or load just the package options &mdash;all of them&mdash; with the `imgnoiser.options.save()` and `imgnoiser.options.load()` functions.

```{r echo=TRUE, eval=FALSE}
# Save the current package options
imgnoiser.options.save('this.options')

# In another R session, load the saved package options
imgnoiser.options.load('this.options')
```

It is not required to specify the extension in the file names, if actually it is not `.imn`, that extension will be appended to the given file name.

&crarr;
