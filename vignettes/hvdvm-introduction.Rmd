---
title: "*hvdvm* Class Introduction"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    css: odlvignette.css
    number_sections: yes
vignette: >
  %\VignetteIndexEntry{hvdvm Class Introduction}
  %\VignetteEngine{knitr::rmarkdown}
  %\usepackage[utf8]{inputenc}
---

```{r echo = FALSE, message = FALSE}
library(imgnoiser)
options(digits=4)
test.data.folder <- imgnoiser:::get.test.data.folder()

knitr::opts_chunk$set(
     comment = "#>"
    ,prompt = FALSE
    ,collapse = TRUE
    ,dev = 'png'
    ,tidy = FALSE
  )
#rmarkdown::render("./vignettes/hvdvm-introduction.Rmd", output_format='md_document')
```

The acronym *hvdvm* stands for "Half-Var-Delta versus Mean" and refers to a technique to remove the PRNU noise from digital camera raw images, by the use of two *"identical"* digital photographs, i.e. photos of the same scene, with identical setup, camera settings and target scene; as two consecutive images of a still target in a shooting burst. This technique is employed to characterize a digital camera sensor noise response.

Without the PRNU noise component, the `variance` and the `mean` of the pixel values in a raw image file are expected to have a linear relationship. To measure sensor noise and not the light and shadows from the target scene, we are talking about a raw image file from the photograph of a uniformly lit plain surface (e.g a white cardboard). 

This technique is useful to measure some particular camera sensor characteristics. With the PRNU noise removed, the coefficients of the linear fit between the variance and the `mean` of the pixel values are:

* **Slope**: the camera sensor conversion ratio from electrons to ADUs.
* **Intercept**: the Read Noise variance.

The procedure is applied to the raw data from each of the four photosite channels (colors) in the sensor 2x2 RGB [Bayer filter](http://en.wikipedia.org/wiki/Bayer_filter), bringing four independent linear fittings. 

The theoretical basis of this approach is explained in the article [*"A Simple DSLR Camera Sensor Noise Model"*](http://www.odelama.com/photo/A-Simple-DSLR-Camera-Sensor-Noise-Model/#theo-hvdvm), while the [*"Use of Linear Regressions to Model Camera Sensor Noise"*](http://www.odelama.com/photo/Use-of-Linear-Regressions-to-Model-Camera-Sensor-Noise/#hvdvm-def) describes the practical application of that model. The article [*"Handling Heteroscedastic Data from Camera Sensor Noise"*](http://www.odelama.com/data-analysis/Handling-Heteroscedastic-Data-from-Camera-Sensor-Noise/#h-solve-hetero) explains how to handle the heteroscedasticity that appear in the data computed by the `hvdvm` and `vvm` class.

In the code examples, the function output is presented prefixed with `#>`, while a single prefix `#` represents real (user) comments.


<div id="TOC">
<div class="toctitle">Table of Contents </div>
- [The *hvdvm* procedure](#hvdvm-proc)
- [Input Data for the *hvdvm* Class](#hvdvm-input)
- [Creating a *hvdvm* Instance](#create)
- [Digesting the Image Samples](#digest)
- [Getting the Computed Values](#result)
    * [Variance Result](#var)
    * [Covariance Result](#cov)
- [Usage of other *hvdvm* Functions](#other)
- [Summary of *hvdvm* Members](#methods)
</div>


# The *hvdvm* procedure {#hvdvm-proc}

The procedure needs as input two image samples from two *identical* raw photo files. To remove the PRNU noise, the procedure *"synthesizes"* an image by subtracting each pixel value from one image sample to the corresponding pixel in the other. The half of the pixel values variance of that *synthesized* image is expected to have the same variance of those original samples but with the PRNU quadratic variance component removed. 

In the `imgnoiser::hvdvm` class, the half of the pixel values variance from the *synthesized* image is called  `Half-Var-Delta` for short. The `Half-Var-Delta` and the `Mean` photosites values are expected to have a linear relationship. The `Mean` photosites values is computed from the average pixel values from both *identical* images. This is like *synthetizing* another image built by averaging each corresponding pixel on each sample. This computation is made using floating point arithmetic. At the end, the pixels in this last *synthetic* image are averaged to get the `mean` value that will be fitted against the `Half-Var-Delta` variable or `hvdvm` for short.

Without the proper tools, the application of this technique is labor intensive, slow and error prone. The `hvdvm` class contains well suited tools to automatize the process and make it easy to apply over a large set of samples.

# Input Data for the *hvdvm* Class {#hvdvm-input}

We need a set of image file samples, with the [`FITS`](http://fits.gsfc.nasa.gov/) or the [`PGM`](http://netpbm.sourceforge.net/doc/pgm.html) format, from shots taken to a uniformly lit flat plain surface. The vignette [*Collecting Image Samples"*](collecting-samples.html) contains a thorough explanation about how to get those image samples.

As we have already seen, we will need pairs of photographs taken under identical conditions. The functions in the `hvdvm` class will process every pair of samples from photographs taken under the same conditions (regardless of their order). 

Using the `choose()` function we can compute the number of pair combinations for a given number of *identical* shots. For example from 6 shots taken in the same conditions, 15 combinations will be processed by the class (bringing 15 observations for the model fitting).

```{r }
choose(6, 2)
```

The `hvdvm` class needs information to identify the shots taken under identical conditions in the form of a .csv file, which we will call the *photo conditions file*. We can build that file using [ExifTool](http://www.sno.phy.queensu.ca/~phil/exiftool/) (free software), for example using the following command  (windows example).

    exiftool.exe -common -sort -ext nef -csv ./ > ISO100Conds.csv

This command will extract *common* (`-common`) exif metadata from the Nikon '.nef' image files (`-ext nef`) in the current directory (`./`) using the .csv format (`-csv`) and the output will be sorted by photo file name (`-sort`). The output redirection (`> ISO100Conds.csv`) will save the command output into the `"ISO100Conds.csv"` file in the current directory. We must edit this file to get at the end one containing this column names:

```{r, echo = FALSE, message = FALSE, results = "hide"}
csv.df <- read.csv(paste0(test.data.folder,'iso100White.csv'))
csv.df <- csv.df[1:6,c('crop.file.name', 'photo.file.name', 'lighting', 'ISO', 'shutter.speed', 'aperture', 'focal.length')]
```

```{r, echo = FALSE, comment=" " } 
knitr::kable(head(csv.df), caption='**iso100White.csv input file example**', align=c('c','c','c','c','r','c','r'))
```

The exact column names you will get from the `ExifToool.exe` command depend on your camera brand. However they will be easy to identify. 

The `hvdvm` class expects the *photo conditions file* contains the following columns.

* `crop.file.name`
* `lighting`
* `ISO`
* `shutter.speed` (exposition time)
* `aperture`
* `focal.length`

The sequence of the columns is not significant and there can be also other columns. Except for `crop.file.name` the exact values in these columns are not important, the procedure will just distinguish the differente values in them. For example, `shutter.speed` can contain `'1/50'` or `0.02` or just `'50'`.

The names of these columns is required exactly as shown in the list above. However, there is an option in the `hvdvm` to make a mapping from other column names to this ones.

Notice the `crop.file.name` and `lighting` columns do not come in the `ExifTool` .csv file. We must add those columns to the .csv file "by hand". The `crop.file.name` is the name of the sample image file cropped from the photo file indicated in the column `FileName` in the output of ExifTool. 

As the rows in the `ExifTool` .csv file are sorted by photo file name, and the the crop files has a name with with an increasing numeric suffix (e.g. `crop_1.fit`, `crop_2.fit`, etc.) with the same sequence of the .csv sorted photo file names (that is the way `Iris` software will produce those crops), we can easily add the `crop.file.name` column and set the value `crop_1.fit` for the first row, `crop_2.fit` for the second one and so on.

It is very important the crop file names and the photo file names are correctly matched, otherwise images taken with differente conditions will be paired, producing unexpected and invalid results. Furthermore, the crop file names should also be correct, so the class can open and read those image files, they must not include the file path, but just the file name and extension (e.g. `crop_12.fit`).

Finally we need to add the `lighting` column with information based on our notes about the changes in the intensity of the light over the target scene. The exact values for this column are not important. The class will just distinguish between the different values of this variable.

To begin with, you can fill the column with the value `Normal` and for those photos with higher lighting we can set the label `high`. If you increased the lighting twice during the shooting session, you can correspondingly tag those photos with the values `high A` and `high B` in the `lighting` column. Proceed with the same labeling schema for the shoots with lower lighting.

# Creating a *hvdvm* Instance # {#create}

To make use of the `hvdvm` class, and in general any other classes in the package. we need first to create an instance of the class, which is done calling the class `new` function. This function name for instance creation is standardized, so every class contains this function. For example there are `hvdvm$new()` and `vvm$new()` functions. 

The output of this instance constructor function is what is called a class instance object. This way the output of the `hvdvm$new()` function is a `hvdvm` instance object. 

Once we have an object of the class, we can access to the class functions and variables through that particular object. For example:

```{r eval=FALSE}
# Create an 'hvdvm' instance object and save it in the 'my.hvdvm.object' variable
my.hvdvm.object <- hvdvm.new()
# Starting from here we access to all the class functions and variables using the
# instance object
my.hvdvm.object$digest('iso100White.csv')
```

Of course, we can create many instances, for the processing of the same or different image samples.

We will create and save an instance of the `hvdvm` class assuming our image samples have the RGGB pattern for the layout of the photosites color filters. we can get detailed information about the `hvdvm$new()` function parameters, with the command:

```{r eval=FALSE}
help('hvdvm$new')
```

We will save our instance object in the `my.hvdvm` variable.

```{r}
my.hvdvm <- hvdvm$new(has.RGGB.pattern = TRUE)
```

If we print this variable, we will get --in a nice style-- a list of its members. Those are the class members you can use, with exception to those whose name start with a period `.` which are meant for internal use only.

```{r}
my.hvdvm
```

Notice in the above list, there are some elements with the "active binding" tag. We will call them object variables or just variables. We will explain their use along this document.

# Digesting the Image Samples {#digest}

The function that reads and process the image samples using the *hvdm* technique is called `digest()`. We must feed that function with a `.csv` file, prepared as described in the section [*"Input data for the *hvdvm* Procedure"*](#hvdvm-input). 

For this example, the file is named `iso100White.csv` and looks like this:

```{r, echo=FALSE, message=FALSE, results="hide"}
csv.df <- read.csv(paste0(test.data.folder,'iso100White.csv'))
csv.df <- csv.df[1:6,c('crop.file.name', 'photo.file.name', 'lighting', 'ISO', 'shutter.speed', 'aperture', 'focal.length')]
```

```{r, echo=FALSE, comment=" " } 
knitr::kable(head(csv.df), caption='**iso100White.csv input file example**', align=c('c','c','c','c','r','c','r'))
```

In this example, the `.csv` file and the image samples, whose names are in the `crop.file.name` column in the `.csv` file, are both in the current working directory.

The `.csv` file must include the following columns:

* `crop.file.name`
* `lighting`
* `ISO`
* `shutter.speed`
* `aperture`
* `focal.length`

The columns must be named exactly as in the above list. This means, if any of them is named differently, you must rename it, or change the `conds.col.map` option value (with the `imgnoiser.option()` function) to make it map your `.csv` actual column names with the expected ones. The `.csv` file can contain other columns, they will be just ignored. 

When the `show.progress` option is `TRUE`, as it is by default, a progress bar will appear showing you how much of the process was already done. If that option is `FALSE`, as in this example, at the end of the processing, the `digest()` function will print a message about how many sample combinations were processed.

```{r echo=FALSE, message=FALSE, results="hide"}
imgnoiser.option('show.progress', FALSE)
my.hvdvm$digest(paste0(test.data.folder,'iso100White.csv'), test.data.folder)
```

```{r eval=FALSE}
imgnoiser.option('show.progress', FALSE)
# The image files are in the './img/' folder
my.hvdvm$digest('iso100White.csv', './img/')
# 80 different sample combinations were processed.
```

# Getting the Computed Values # {#result}

The `hvdvm$digest()` function computes and saves *variance* and *covariance* information from the photosites values in your image samples, which you can read after its processing.

## Variance Result ## {#var}

we can get the resulting *variance*, reading the `hvdvm$var.df` variable. 

For the `hvdvm` technique used by this class, this variance is half of the variance in the delta image, computed for each channel in the image samples.

```{r eval=FALSE}
# Get the computed variance
head(my.hvdvm$var.df)
```

```{r, echo=FALSE, comment=" " } 
knitr::kable(head(my.hvdvm$var.df), caption='**Variance and Mean results**', align=c('c','l','l','r','r','r'), digits=2)
```

The `pict1` and `pict2` fields in each row, show the sample image file names to which the `hvdvm` procedure was applied. According with the data in the input `.csv` file, they come from photographs taken under identical conditions. The first `cond` column, refers --with a sequential number-- to the photographic conditions used to shot those samples. Different `cond` values represent different photographic conditions and vice versa. 

We can get the different photographic conditions reading the `hvdvm$photo.conditions.df` variable.

```{r eval=FALSE}
# Get the different photographic conditions
head(my.hvdvm$photo.conditions.df)
```

```{r, echo=FALSE, comment=" " } 
knitr::kable(head(my.hvdvm$photo.conditions.df), caption='**Photographic Conditions**', align=c('c','c','c','r','c','r','c'))
```

Now we can see the photographic conditions referred by the column `cond` in the "*Variance* and *Mean* result" shown above.

Coming back to the *Variance and Mean* results, we can see the samples `crop_31.fit`, `crop_32.fit` and `crop_33.fit` were taken under the same photographic conditions, because they appear in rows with the same condition code `1`, which in particular, as we can see above, corresponds to `1/100` of shutter speed (or exposition time).

Notice by the `channel` factor how the procedure was applied independently to each of the four channels in each pair of samples. So, there are four rows with the same `cond`, `pict1` and `pict2` column values but with different computed values of `mean` and `var` (*variance*) for each channel.

The column `var`, as product of the `hvdvm` technique, contains the half of the photosite values variance of the difference image, computed subtracting the pixel values of `pict1` from the corresponding ones in the `pict2` sample (the *variance* is independent of the subtraction order). The column `mean` is the mean of the photosites values of the average image, averaging each pixel value of `pict1` with the corresponding one in the `pict2` sample.

Now we can plot the data showing the relationship between the `var` and the `mean` variables for each `channel`. 

```{r fig.width=6.5, fig.height=6, fig.align='center'}
# Plot the data in the standard model
my.hvdvm$plot(warnings=TRUE)
```

We will see later the use of the plot function in more detail.

## Covariance Result ## {#cov}

The `hvdvm$digest()` function also computes the *covariance* between each pair of channels in the delta image. We get that *covariance* data reading the `hvdvm$cov.df` variable.

In the following data frame, the columns `chan.a` and `chan.b` show the channels whose *covariance* is shown in the `cov` column. All the other columns have the same meaning as in the *variance* data in the `hvdvm$var.df` variable we saw above.

```{r eval=FALSE}
# Get the computed covariance
head(my.hvdvm$cov.df)
```

```{r, echo=FALSE, comment=" " } 
knitr::kable(head(my.hvdvm$cov.df), caption='**Covariance result**', align=c('c','r','r','r','r','r'), digits=2)
```

For the `hvdvm` technique, this data contains the half of the *covariance* in the delta image, for each pair of channels combination.

# Usage of Other *hvdvm* Functions # {#other}

There are more `hvdvm` class functions you can call from your class object, they are introduced in the [*"hvdvm and vvm Class Usage"* vignette](hvdvm-and-vvm-usage.html).

# Summary of `hvdvm` Members # {#methods}

You can get this summary issuing the R command `help('hvdvm')`. However, the format in that help is not as easy to read like this.

## new() ##

Create a new instance of the hvdvm class.

```R
new(
channel.labels = imgnoiser.option("channel.labels"),
green.channels = imgnoiser.option("green.channels"),
has.RGGB.pattern = imgnoiser.option("has.RGGB.pattern"),
avg.green.label = imgnoiser.option("avg.green.channel.label")
)
```

## digest() ##

Compute and collect statistics from the raw images files.

```R
digest(
  photo.conds.file = stop("The 'photo.conds.file' argument is required."),
  crop.files.path = './'
)
```

## var.df ##

Get the resulting noise variance data.

```R
var.df
```

## cov.df ##

Get the resulting noise covariance data.

```R
cov.df
```

## photo.conditions.df ##

Get the distinct photographic conditions.

```R
photo.conditions.df
```

## channel.labels ##

Get the channel labels.

```R
channel.labels
```

## green.channels ##

Get the green channels indices.

```R
green.channels
```

## fit.model() ##

Fit a model to the noise data.

```R
fit.model(
  model.name = imgnoiser.option("fit.model.name"),
  model.family = imgnoiser.option("fit.model.family"),
  degree = 1L,
  formula = NULL,
  model.data.name = imgnoiser.option("fit.model.data"),
  ...
)
```

## print.model.summary() ##

Print a fitted model summary.

```R
  print.model.summary(
  model.name = imgnoiser.option("fit.model.name"),
  select = NULL,
  ...
)
```

## get.model.predictions() ##

Get the values predicted by a fitted model.

```R
get.model.predictions(
  model.name = imgnoiser.option("fit.model.name")
)
```

## get.model() ##

Get a fitted model object.

```R
get.model(
  model.name = imgnoiser.option("fit.model.name"),
  select = NULL
)
```

## exists.model() ##

Find if a model with a given name has already been fitted.

```R
exists.model(
  model.name = imgnoiser.option("fit.model.name")
)
```

## model.list ##

Get a list with the fitted models.

```R
model.list
```

## remove.model() ##

Remove a fitted model.

```R
remove.model(
  model.name = stop("A model name argument is required.")
)
```

## plot() ##

Plot a fitted model and its source data.

```R
plot(
  model.name = FALSE,
  obs = TRUE,
  print = TRUE,
  fit = TRUE,
  confid = FALSE,
  main = NA,
  subt = NA,
  xlab = NA,
  ylab = NA,
  xlim = NULL,
  ylim = NULL,
  warnings = FALSE
)
```


&crarr;
